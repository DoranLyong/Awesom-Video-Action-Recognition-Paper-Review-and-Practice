# Paper Contents & Review 

The following paper lists are what I did or will read, and they might not cover all papers published so far.



---

## Table of Contents (ongoing)

* Statistics 
* Survey 
* Conferences 
  * 2021 update 
  * 2020 update 
  * 2018 update 
  * 2017 update 
  * 2016 update
* Others 
* Datasets 

---

## Statistics 

| Conference  | Link | #Total | Video Understanding | Action Classification | Action Recognition | Activity Recognition | Motion Prediction |
|---           |---   |---|---|---|---|---|---           |



---

## Survey 

> 1. Video Action Understanding, IEEE Access 2021 [[paper](https://ieeexplore.ieee.org/abstract/document/9548074)]
> 2. A Comprehensive Study of Deep Video Action Recognition, arXiv2020 [[paper](https://arxiv.org/abs/2012.06567v1)] [[code](https://paperswithcode.com/paper/a-comprehensive-study-of-deep-video-action)] [[3rd src](https://bryanyzhu.github.io/videomodeling.github.io/)]



## Conference

CVPR, ECCV, ICCV, WACV, ICPR



### CVPR2021

> 1. 2nd  Comprehensive Tutorial on Video Modeling, CVPR2021 tutorial [[page](https://bryanyzhu.github.io/video-cvpr2021/)]



### CVPR2020

> 1. 1st Comprehensive Tutorial on Video modeling, CVPR2020 tutorial [[page](https://bryanyzhu.github.io/videomodeling.github.io/)]
> 2. X3D: Expanding Architectures for Efficient Video Recognition, CVPR2020 [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Feichtenhofer_X3D_Expanding_Architectures_for_Efficient_Video_Recognition_CVPR_2020_paper.html)] [[code](https://paperswithcode.com/paper/x3d-expanding-architectures-for-efficient)] [[3rd code](https://reposhub.com/python/deep-learning/kkahatapitiya-X3D-Multigrid.html)]
> 3. Future Video Synthesis with Object Motion Prediction, CVPR2020 [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Wu_Future_Video_Synthesis_With_Object_Motion_Prediction_CVPR_2020_paper.html)] [[code](https://paperswithcode.com/paper/future-video-synthesis-with-object-motion)]



### ECCV2020 

> 1. RubiksNet: Learnable 3D-Shift for Efficient Video Action Recognition, ECCV2020 [[paper](https://stanfordvl.github.io/rubiksnet-site//assets/eccv20.pdf)] [[code](https://github.com/StanfordVL/RubiksNet)] [[page](https://stanfordvl.github.io/rubiksnet-site/)] [[youtube](https://youtu.be/NSnx4ueEQow)]



### WACV2020 

> 1. Dynamic Motion Representation for Human Action Recognition, WACV2020 [[paper](https://openaccess.thecvf.com/content_WACV_2020/html/Asghari-Esfeden_Dynamic_Motion_Representation_for_Human_Action_Recognition_WACV_2020_paper.html)] [[youtube](https://youtu.be/zZDhauFsOUo?t=1101)]



### ICPR2020

> 1. Learning Group Activities from Skeletons without Individual Action Labels [[paper](https://ieeexplore.ieee.org/document/9413195)] [[code](https://github.com/fabiozappo/SkeletonGroupActivityRecognition)] [[video](https://underline.io/lecture/12516-2894---learning-group-activities-from-skeletons-without-individual-action-labels)]



### ICCV2019 

> 1. TSM: Temporal Shift Module for Efficient Video Understanding, ICCV2019 [[paper](https://openaccess.thecvf.com/content_ICCV_2019/html/Lin_TSM_Temporal_Shift_Module_for_Efficient_Video_Understanding_ICCV_2019_paper.html)] [[code](https://paperswithcode.com/paper/temporal-shift-module-for-efficient-video)] [[youtube](https://youtu.be/4BwXOcLqrGk)]



### CVPR2019

> 1. Learning Actor Relation Graphs for Group Activity Recognition, CVPR2019 [[paper](https://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Learning_Actor_Relation_Graphs_for_Group_Activity_Recognition_CVPR_2019_paper.html)] [[code](https://paperswithcode.com/paper/learning-actor-relation-graphs-for-group)]



### ECCV2018 

> 1. DYAN: A Dynamical Atoms-Based for Video Prediction, ECCV2018 [[paper](https://openaccess.thecvf.com/content_ECCV_2018/html/Wenqian_Liu_DYAN_A_Dynamical_ECCV_2018_paper.html)]



### CVPR2018

> 1. What Have We Learned From Deep Representations for Action Recognition?, CVPR2018 [[paper](https://openaccess.thecvf.com/content_cvpr_2018/html/Feichtenhofer_What_Have_We_CVPR_2018_paper.html)] [[page](https://feichtenhofer.github.io/)] [[3rd src](https://feichtenhofer.github.io/pubs/Feichtenhofer_Actions_FVT_2017.pdf)] [[supp](http://feichtenhofer.github.io/action_vis.pdf?utm_source=catalyzex.com)]



### ICCV2017

> 1. What Actions are Needed for Understanding Human Action in Videos?, ICCV2017 [[paper](https://openaccess.thecvf.com/content_iccv_2017/html/Sigurdsson_What_Actions_Are_ICCV_2017_paper.html)] [[code](https://paperswithcode.com/paper/what-actions-are-needed-for-understanding)]



### ECCV2016

> 1. Temporal Segment Networks (TSN): Towards Good Practices for Deep Action Recognition, ECCV2016 [[paper](https://arxiv.org/abs/1608.00859v1)] [[code](https://paperswithcode.com/paper/temporal-segment-networks-towards-good)] [[PAMI ver](https://ieeexplore.ieee.org/abstract/document/8454294)]

